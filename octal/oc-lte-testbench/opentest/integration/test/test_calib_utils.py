import unittest
from opentest.integration import calib_utils
from mock import MagicMock

class TestCalibUtils(unittest.TestCase):

    def setUp(self):
        self.FIRST_FREQ = 1805
        self.LAST_FREQ = 1821
        self.freq_range = range(self.FIRST_FREQ, self.LAST_FREQ+1, 5)

        self.tx_attens = []
        self.bb_attens = []
        for freq in self.freq_range:
            if freq % 2 == 0:
                self.bb_attens.append(30)
                self.tx_attens.append(25)
            else:
                self.bb_attens.append(28)
                self.tx_attens.append(30)

        self.bb_table = calib_utils.LTEBBCalibTable().set_values(self.freq_range, 20, self.bb_attens)
        self.tx_table = calib_utils.LTETXCalibTable().set_values(self.freq_range, range(30, 31), 20, self.tx_attens)

    # def test_simple_calib_table_interpolation(self):
    #     interpolated_attens = self.interpolate_bb_table()
    #     self.simple_validate_interpolated_attens(interpolated_attens, self.bb_attens)
    #
    # def test_calib_table_interpolation_with_affecting_table(self):
    #     bb_interpolated_table = self.interpolate_bb_table()
    #     tx_interpolated_table = self.tx_table.interpolate_table(affecting_attens=bb_interpolated_table, this_to_affecting_ratio=-4)
    #     # print(bb_interpolated_table)
    #     # print(tx_interpolated_table)
    #     self.simple_validate_interpolated_attens(tx_interpolated_table, self.tx_attens)

    def simple_validate_interpolated_attens(self, table, orig_attens):
        for orig_atten in orig_attens:
            self.assertIn(orig_atten, table)
        self.assertEqual(orig_attens[0], table[0])
        self.assertEqual(orig_attens[-1], table[-1])
        self.assertEqual(len(table), self.LAST_FREQ-self.FIRST_FREQ)


    def interpolate_bb_table(self):
        return self.bb_table.interpolate_table()

class TestGenericCalibTable(unittest.TestCase):

    def test_sorted_insert(self):
        table = calib_utils.Generic1DCalibTable()
        table.add_measure(1800, 50)
        table.add_measure(1780, 50)
        self.assertEqual(1780, table.measures[0][0])

    def test_interpolate(self):
        table = calib_utils.Generic1DCalibTable()
        table.add_measure(1800, 60)
        table.add_measure(1780, 50)
        value = table.interpolate(1790)

        self.assertEqual(value, 55)

    def test_interpolate_range(self):
        table = calib_utils.Generic1DCalibTable()
        table.add_measure(1800, 60)
        table.add_measure(1780, 50)
        value = table.interpolate_range([1780, 1785, 1790, 1795, 1800])

        self.assertEqual(value, [50, 52.5, 55, 57.5, 60])

    def test_interpolate_step(self):
        table = calib_utils.Generic1DCalibTable()
        table.add_measure(1800, 60)
        table.add_measure(1780, 50)
        value = table.interpolate_step(5, include_end=True)

        self.assertEqual(value, [50, 52.5, 55, 57.5, 60])

    def test_interpolate_linspace(self):
        table = calib_utils.Generic1DCalibTable()
        table.add_measure(1800, 60)
        table.add_measure(1780, 50)
        value = table.interpolate_linspace(5)

        self.assertEqual(value, [50, 52.5, 55, 57.5, 60])
